{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvinashReddy-47/BeatSwap_AI/blob/main/notebooks\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚öôÔ∏è Audio/DSP + Web UI\n",
        "!pip install spleeter librosa soundfile pydub numpy gradio\n",
        "\n",
        "# üß∞ System dep for audio I/O\n",
        "!apt-get -y install -qq ffmpeg\n"
      ],
      "metadata": {
        "id": "k7bOkBzoW7T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Python imports we'll use throughout the project ---\n",
        "import os, sys, json, glob, zipfile, shutil, math, tempfile, uuid, warnings\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# --- Project paths ---\n",
        "ROOT_DIR      = os.getcwd()\n",
        "DATA_DIR      = os.path.join(ROOT_DIR, \"data\")\n",
        "BEATS_DIR     = os.path.join(DATA_DIR, \"beats\")      # your beats dataset lives here\n",
        "UPLOADS_DIR   = os.path.join(DATA_DIR, \"uploads\")    # user-uploaded songs (website input)\n",
        "STEMS_DIR     = os.path.join(DATA_DIR, \"stems\")      # separated stems (vocals/music)\n",
        "OUTPUTS_DIR   = os.path.join(ROOT_DIR, \"outputs\")    # final remixes\n",
        "INDEX_PATH    = os.path.join(DATA_DIR, \"beats_index.json\")  # precomputed BPM/key index for beats\n",
        "\n",
        "# --- Make sure folders exist ---\n",
        "for d in [DATA_DIR, BEATS_DIR, UPLOADS_DIR, STEMS_DIR, OUTPUTS_DIR]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# --- Nice printing to confirm ---\n",
        "print(\"‚úÖ Imports loaded.\")\n",
        "print(\"üìÇ Folders ready:\")\n",
        "print(\"  ROOT_DIR   :\", ROOT_DIR)\n",
        "print(\"  DATA_DIR   :\", DATA_DIR)\n",
        "print(\"  BEATS_DIR  :\", BEATS_DIR)\n",
        "print(\"  UPLOADS_DIR:\", UPLOADS_DIR)\n",
        "print(\"  STEMS_DIR  :\", STEMS_DIR)\n",
        "print(\"  OUTPUTS_DIR:\", OUTPUTS_DIR)\n",
        "print(\"  INDEX_PATH :\", INDEX_PATH)\n"
      ],
      "metadata": {
        "id": "YW4HA00qZEgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Upload your beats ZIP (70 files) ---\n",
        "print(\"‚¨ÜÔ∏è Please upload your BEATS ZIP (contains .wav/.mp3/etc).\")\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "beats_zip = list(uploaded.keys())[0]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XnAKMoh4ZEdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Extract into BEATS_DIR ---\n",
        "import zipfile, glob, os, json\n",
        "with zipfile.ZipFile(beats_zip, 'r') as z:\n",
        "    z.extractall(BEATS_DIR)\n",
        "\n",
        "# --- Find all audio files in the beats folder ---\n",
        "AUDIO_EXTS = (\"*.wav\",\"*.mp3\",\"*.flac\",\"*.m4a\",\"*.ogg\")\n",
        "beats_files = []\n",
        "for ext in AUDIO_EXTS:\n",
        "    beats_files += glob.glob(os.path.join(BEATS_DIR, \"**\", ext), recursive=True)\n",
        "\n",
        "print(f\"‚úÖ Found {len(beats_files)} beat files in {BEATS_DIR}\")\n",
        "assert len(beats_files) > 0, \"No audio files found in your beats ZIP. Check the archive structure.\"\n",
        "\n",
        "# --- Analysis helpers: estimate BPM + key ---\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "PITCH_CLASSES = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
        "\n",
        "def estimate_bpm_key(path: str, max_duration: float = 60.0):\n",
        "    \"\"\"\n",
        "    Load up to `max_duration` sec, mono; estimate BPM via beat_track,\n",
        "    and key by max chroma bin.\n",
        "    \"\"\"\n",
        "    y, sr = librosa.load(path, sr=None, mono=True, duration=max_duration)\n",
        "    if y.size == 0:\n",
        "        raise ValueError(\"Empty audio loaded.\")\n",
        "\n",
        "    # BPM\n",
        "    bpm, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
        "    bpm = float(bpm) if np.isfinite(bpm) else 0.0\n",
        "\n",
        "    # Key (coarse): argmax of mean chroma\n",
        "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
        "    chroma_mean = chroma.mean(axis=1)\n",
        "    key_idx = int(np.argmax(chroma_mean))\n",
        "    key_name = PITCH_CLASSES[key_idx]\n",
        "    return bpm, key_idx, key_name\n",
        "\n",
        "# --- Analyze all beats and build index ---\n",
        "index = []\n",
        "errors = []\n",
        "for i, bf in enumerate(sorted(beats_files)):\n",
        "    try:\n",
        "        bpm, key_idx, key_name = estimate_bpm_key(bf, max_duration=60.0)\n",
        "        rel_path = os.path.relpath(bf, start=BEATS_DIR)\n",
        "        index.append({\n",
        "            \"path\": rel_path,          # stored relative to BEATS_DIR for portability\n",
        "            \"bpm\": round(bpm, 2),\n",
        "            \"key_idx\": int(key_idx),\n",
        "            \"key_name\": key_name\n",
        "        })\n",
        "        if i % 5 == 0:\n",
        "            print(f\"[{i+1}/{len(beats_files)}] {os.path.basename(bf)[:40]:40s} ‚Üí BPM={bpm:6.2f}  Key={key_name}\")\n",
        "    except Exception as e:\n",
        "        errors.append((bf, str(e)))\n",
        "        print(f\"‚ö†Ô∏è Skip: {bf} ‚Üí {e}\")\n",
        "\n",
        "# --- Save index for later fast matching in the web app ---\n",
        "with open(INDEX_PATH, \"w\") as f:\n",
        "    json.dump(index, f, indent=2)\n",
        "\n",
        "print(\"\\nüìÅ Saved beats index:\", INDEX_PATH)\n",
        "print(f\"‚úÖ Indexed {len(index)} beats  |  ‚ö†Ô∏è Skipped {len(errors)}\")\n",
        "if errors:\n",
        "    print(\"   (Some files failed to analyze; usually very short/corrupt.)\")\n",
        "\n",
        "# Quick peek at first few entries\n",
        "print(\"\\nüîé Example entries:\")\n",
        "print(json.dumps(index[:3], indent=2))"
      ],
      "metadata": {
        "id": "RsyNRU-f4-9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Upload a full song and split with Spleeter (2 stems) ---\n",
        "from google.colab import files\n",
        "import os, shutil, subprocess, glob\n",
        "\n",
        "# Expect folders from Block 2:\n",
        "# DATA_DIR, UPLOADS_DIR, STEMS_DIR already defined there\n",
        "\n",
        "print(\"‚¨ÜÔ∏è Please upload the FULL SONG (mp3/wav/m4a/ogg).\")\n",
        "up = files.upload()\n",
        "user_filename = list(up.keys())[0]\n",
        "\n",
        "# Save to uploads dir\n",
        "os.makedirs(UPLOADS_DIR, exist_ok=True)\n",
        "user_in_path = os.path.join(UPLOADS_DIR, user_filename)\n",
        "if os.path.abspath(user_filename) != os.path.abspath(user_in_path):\n",
        "    shutil.move(user_filename, user_in_path)\n",
        "print(\"‚úÖ Saved user song:\", user_in_path)\n",
        "\n",
        "# Run Spleeter 2-stems (vocals + accompaniment)\n",
        "os.makedirs(STEMS_DIR, exist_ok=True)\n",
        "cmd = [\n",
        "    \"spleeter\", \"separate\",\n",
        "    \"-p\", \"spleeter:2stems\",     # model: vocals + accompaniment\n",
        "    \"-o\", STEMS_DIR,             # output root\n",
        "    user_in_path                 # input file\n",
        "]\n",
        "print(\"‚ñ∂Ô∏è Running:\", \" \".join(cmd))\n",
        "res = subprocess.run(cmd, capture_output=True, text=True)\n",
        "print(\"------ Spleeter STDOUT ------\")\n",
        "print(res.stdout)\n",
        "print(\"------ Spleeter STDERR ------\")\n",
        "print(res.stderr)\n",
        "\n",
        "# Locate resulting folder (named after the uploaded file base)\n",
        "base = os.path.splitext(os.path.basename(user_in_path))[0]\n",
        "out_dir = os.path.join(STEMS_DIR, base)\n",
        "\n",
        "vocals_path = os.path.join(out_dir, \"vocals.wav\")\n",
        "acc_path    = os.path.join(out_dir, \"accompaniment.wav\")\n",
        "\n",
        "# Sanity checks\n",
        "assert os.path.exists(vocals_path), f\"‚ùå vocals.wav not found in {out_dir}\"\n",
        "assert os.path.exists(acc_path),    f\"‚ùå accompaniment.wav not found in {out_dir}\"\n",
        "\n",
        "print(\"‚úÖ Stems ready:\")\n",
        "print(\"  Vocals:\", vocals_path)\n",
        "print(\"  Music :\", acc_path)\n"
      ],
      "metadata": {
        "id": "iT59jt8LdhFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, glob\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# ---------- Resolve paths ----------\n",
        "# Reuse variables from earlier blocks if present; otherwise infer.\n",
        "try:\n",
        "    VOCALS_PATH = vocals_path  # from Block 4\n",
        "except NameError:\n",
        "    # Find the newest vocals.wav under STEMS_DIR\n",
        "    cand = glob.glob(os.path.join(STEMS_DIR, \"**\", \"vocals.wav\"), recursive=True)\n",
        "    assert cand, \"No vocals.wav found. Please run Block 4 first.\"\n",
        "    VOCALS_PATH = max(cand, key=os.path.getmtime)\n",
        "\n",
        "try:\n",
        "    INDEX_JSON = INDEX_PATH  # from Block 2\n",
        "except NameError:\n",
        "    INDEX_JSON = \"/content/data/beats_index.json\"\n",
        "\n",
        "BEATS_ROOT = BEATS_DIR if 'BEATS_DIR' in globals() else \"/content/data/beats\"\n",
        "\n",
        "print(\"üé§ VOCALS_PATH:\", VOCALS_PATH)\n",
        "print(\"üìÅ INDEX_JSON :\", INDEX_JSON)\n",
        "print(\"üìÇ BEATS_ROOT :\", BEATS_ROOT)\n",
        "\n",
        "# ---------- Music theory helpers ----------\n",
        "PITCH_CLASSES = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
        "\n",
        "def key_distance(a_idx: int, b_idx: int) -> int:\n",
        "    \"\"\"Smallest distance on 12-TET circle (0..11)\"\"\"\n",
        "    d = abs(a_idx - b_idx) % 12\n",
        "    return min(d, 12 - d)\n",
        "\n",
        "# ---------- Feature extraction on vocals ----------\n",
        "def estimate_vocals_features(path: str):\n",
        "    y, sr = librosa.load(path, sr=None, mono=True)\n",
        "    # BPM\n",
        "    bpm, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
        "    bpm = float(bpm) if bpm is not None else 0.0\n",
        "    # Key (coarse): max chroma bin\n",
        "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
        "    chroma_mean = chroma.mean(axis=1)\n",
        "    v_key_idx = int(np.argmax(chroma_mean))\n",
        "    v_key_name = PITCH_CLASSES[v_key_idx]\n",
        "    return bpm, v_key_idx, v_key_name\n",
        "\n",
        "v_bpm, v_key_idx, v_key_name = estimate_vocals_features(VOCALS_PATH)\n",
        "print(f\"üéº VOCALS ‚Üí BPM={v_bpm:.2f}  Key={v_key_name} (idx {v_key_idx})\")\n",
        "\n",
        "# ---------- Load beats index ----------\n",
        "with open(INDEX_JSON, \"r\") as f:\n",
        "    beats_index = json.load(f)\n",
        "assert len(beats_index) > 0, \"Beats index is empty. Re-run Block 3.\"\n",
        "\n",
        "# ---------- Score every beat and choose best ----------\n",
        "def score_beat(beat_bpm: float, beat_key_idx: int, target_bpm: float, target_key_idx: int,\n",
        "               w_bpm: float = 1.0, w_key: float = 2.5) -> float:\n",
        "    \"\"\"\n",
        "    Lower score is better.\n",
        "    We weight key matching a bit higher than BPM for musical compatibility.\n",
        "    \"\"\"\n",
        "    kd = key_distance(beat_key_idx, target_key_idx)\n",
        "    bd = abs((beat_bpm or 0.0) - (target_bpm or 0.0))\n",
        "    return w_bpm * bd + w_key * kd\n",
        "\n",
        "scored = []\n",
        "for e in beats_index:\n",
        "    bbpm = float(e.get(\"bpm\", 0.0))\n",
        "    bkey = int(e.get(\"key_idx\", 0))\n",
        "    s = score_beat(bbpm, bkey, v_bpm, v_key_idx)\n",
        "    scored.append((s, e))\n",
        "\n",
        "# pick best (lowest score)\n",
        "scored.sort(key=lambda x: x[0])\n",
        "best_score, best_entry = scored[0]\n",
        "\n",
        "BEST_BEAT_REL = best_entry[\"path\"]             # relative to BEATS_ROOT\n",
        "BEST_BEAT_ABS = os.path.join(BEATS_ROOT, BEST_BEAT_REL)\n",
        "BEST_BEAT_BPM = best_entry[\"bpm\"]\n",
        "BEST_BEAT_KEY = best_entry[\"key_name\"]\n",
        "BEST_BEAT_KEY_IDX = best_entry[\"key_idx\"]\n",
        "\n",
        "print(\"\\nüéØ BEST MATCH\")\n",
        "print(\"  Beat file :\", BEST_BEAT_ABS)\n",
        "print(f\"  Beat BPM  : {BEST_BEAT_BPM:.2f}\")\n",
        "print(f\"  Beat Key  : {BEST_BEAT_KEY} (idx {BEST_BEAT_KEY_IDX})\")\n",
        "print(f\"  Score     : {best_score:.2f}\")\n",
        "\n",
        "# Save for next blocks\n",
        "best_beat_path = BEST_BEAT_ABS\n",
        "vocal_bpm = v_bpm\n",
        "vocal_key_idx = v_key_idx\n"
      ],
      "metadata": {
        "id": "ooLR8YwSeHWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapts `best_beat_path` to `vocal_bpm` and `vocal_key_idx`, saves to outputs/matched_beat.wav\n",
        "# Requires variables from Block 5: best_beat_path, vocal_bpm, vocal_key_idx\n",
        "# Also uses librosa + soundfile (installed earlier)\n",
        "\n",
        "import os, numpy as np, librosa, soundfile as sf\n",
        "from IPython.display import Audio\n",
        "\n",
        "# Safety: define pitch classes if not present\n",
        "try:\n",
        "    PITCH_CLASSES\n",
        "except NameError:\n",
        "    PITCH_CLASSES = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']\n",
        "\n",
        "# Helpers\n",
        "def estimate_bpm_key(path: str, max_duration: float = 60.0):\n",
        "    \"\"\"Estimate coarse BPM+key for an audio file (mono, truncated for speed).\"\"\"\n",
        "    y, sr = librosa.load(path, sr=None, mono=True, duration=max_duration)\n",
        "    if y.size == 0:\n",
        "        return 0.0, 0  # fallback\n",
        "    bpm, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
        "    bpm = float(bpm) if np.isfinite(bpm) else 0.0\n",
        "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
        "    key_idx = int(np.argmax(chroma.mean(axis=1)))\n",
        "    return bpm, key_idx\n",
        "\n",
        "def smallest_semitone_delta(src_idx: int, tgt_idx: int) -> int:\n",
        "    \"\"\"Shortest move on 12-TET circle in semitones, clamped to [-6, +6].\"\"\"\n",
        "    delta = (tgt_idx - src_idx) % 12\n",
        "    if delta > 6:\n",
        "        delta -= 12\n",
        "    return int(delta)\n",
        "\n",
        "def to_stereo(y: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Duplicate mono -> stereo if needed for nicer mixing later.\"\"\"\n",
        "    if y.ndim == 1:\n",
        "        return np.stack([y, y], axis=1)  # (T, 2)\n",
        "    if y.ndim == 2 and y.shape[1] == 1:\n",
        "        return np.repeat(y, 2, axis=1)\n",
        "    return y  # already stereo\n",
        "\n",
        "# Check inputs from prior block\n",
        "assert 'best_beat_path' in globals(), \"best_beat_path missing. Run Block 5 first.\"\n",
        "assert 'vocal_bpm' in globals(), \"vocal_bpm missing. Run Block 5 first.\"\n",
        "assert 'vocal_key_idx' in globals(), \"vocal_key_idx missing. Run Block 5 first.\"\n",
        "\n",
        "print(\"üéØ Adapting beat to vocals‚Ä¶\")\n",
        "print(\"  Beat file :\", best_beat_path)\n",
        "print(f\"  Target BPM: {vocal_bpm:.2f}\")\n",
        "print(f\"  Target Key: {PITCH_CLASSES[vocal_key_idx]} (idx {vocal_key_idx})\")\n",
        "\n",
        "# 1) Get current beat BPM & key (fallback to index numbers if available)\n",
        "beat_bpm_est, beat_key_idx_est = estimate_bpm_key(best_beat_path, max_duration=60.0)\n",
        "if beat_bpm_est <= 0:\n",
        "    print(\"  ‚ö†Ô∏è Beat BPM estimation failed; using vocals BPM as reference.\")\n",
        "    beat_bpm_est = max(60.0, min(180.0, float(vocal_bpm) if vocal_bpm > 0 else 100.0))\n",
        "\n",
        "print(f\"  Beat BPM (est): {beat_bpm_est:.2f}\")\n",
        "\n",
        "# 2) Load the full beat in mono for DSP (fast and robust)\n",
        "y_beat, sr = librosa.load(best_beat_path, sr=None, mono=True)\n",
        "print(f\"  Loaded beat shape: {y_beat.shape}, sr={sr}\")\n",
        "\n",
        "# 3) Time-stretch to match BPM (clamp rate for quality)\n",
        "rate = float(vocal_bpm) / float(beat_bpm_est) if beat_bpm_est > 0 else 1.0\n",
        "rate_clamped = float(np.clip(rate, 0.5, 2.0))  # avoid extreme artifacts\n",
        "if abs(rate - rate_clamped) > 1e-6:\n",
        "    print(f\"  ‚ö†Ô∏è Clamping stretch rate from {rate:.3f} ‚Üí {rate_clamped:.3f}\")\n",
        "rate = rate_clamped\n",
        "\n",
        "y_ts = librosa.effects.time_stretch(y_beat, rate=rate)\n",
        "\n",
        "# 4) After stretching, detect key and pitch-shift to target key (shortest path)\n",
        "_, stretched_key_idx = estimate_bpm_key(best_beat_path, max_duration=20.0)  # quick proxy\n",
        "# Better: estimate on y_ts directly\n",
        "chroma_ts = librosa.feature.chroma_cqt(y=y_ts, sr=sr)\n",
        "src_key_idx = int(np.argmax(chroma_ts.mean(axis=1)))\n",
        "n_steps = smallest_semitone_delta(src_key_idx, vocal_key_idx)\n",
        "print(f\"  Key align: {PITCH_CLASSES[src_key_idx]} (idx {src_key_idx}) ‚Üí \"\n",
        "      f\"{PITCH_CLASSES[vocal_key_idx]} (idx {vocal_key_idx})  |  shift {n_steps:+d} semitones\")\n",
        "\n",
        "y_ps = librosa.effects.pitch_shift(y_ts, sr=sr, n_steps=n_steps)\n",
        "\n",
        "# 5) Save adapted beat (stereo for nicer mixing later)\n",
        "matched_beat_path = os.path.join(OUTPUTS_DIR if 'OUTPUTS_DIR' in globals() else \"outputs\", \"matched_beat.wav\")\n",
        "y_out = to_stereo(y_ps)  # (T, 2)\n",
        "sf.write(matched_beat_path, y_out, sr)\n",
        "print(f\"‚úÖ Matched beat saved: {matched_beat_path}\")\n",
        "print(f\"   Applied time-stretch rate: {rate:.3f}\")\n",
        "print(f\"   Applied pitch shift       : {n_steps:+d} semitones\")\n",
        "\n",
        "# Optional: quick listen\n",
        "try:\n",
        "    display(Audio(matched_beat_path))\n",
        "except Exception as _:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "vqa3Ea7ueLhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Auto-fix tempo (half/double), align onsets, then mix + play\n",
        "# Replaces your previous mixing block.\n",
        "\n",
        "import os, math, glob, numpy as np, librosa, soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# ---------- Resolve paths ----------\n",
        "try:\n",
        "    VOCALS_PATH\n",
        "except NameError:\n",
        "    # fallback: latest vocals.wav under stems\n",
        "    STEMS_DIR = STEMS_DIR if 'STEMS_DIR' in globals() else \"data/stems\"\n",
        "    cand = glob.glob(os.path.join(STEMS_DIR, \"**\", \"vocals.wav\"), recursive=True)\n",
        "    assert cand, \"No vocals found. Run the separation block first.\"\n",
        "    VOCALS_PATH = max(cand, key=os.path.getmtime)\n",
        "\n",
        "OUTPUTS_DIR = OUTPUTS_DIR if 'OUTPUTS_DIR' in globals() else \"outputs\"\n",
        "os.makedirs(OUTPUTS_DIR, exist_ok=True)\n",
        "\n",
        "# prefer an already-adapted beat if you have it, else use matched_beat.wav from Block 6\n",
        "MATCHED_BEAT = os.path.join(OUTPUTS_DIR, \"matched_beat.wav\")\n",
        "assert os.path.exists(MATCHED_BEAT), \"matched_beat.wav not found. Run the beat-adapt block first.\"\n",
        "\n",
        "print(\"üéöÔ∏è Preparing remix‚Ä¶\")\n",
        "print(\"  Vocals:\", VOCALS_PATH)\n",
        "print(\"  Beat  :\", MATCHED_BEAT)\n",
        "\n",
        "# ---------- Load audio (mono for DSP), unify sample rate ----------\n",
        "y_v, sr_v = librosa.load(VOCALS_PATH, sr=None, mono=True)\n",
        "y_b, sr_b = librosa.load(MATCHED_BEAT, sr=None, mono=True)\n",
        "sr = sr_v\n",
        "if sr_b != sr:\n",
        "    y_b = librosa.resample(y_b, orig_sr=sr_b, target_sr=sr)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def est_bpm(y, sr):\n",
        "    bpm, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
        "    try:\n",
        "        return float(bpm)\n",
        "    except Exception:\n",
        "        return float(bpm.item()) if hasattr(bpm, \"item\") else 0.0\n",
        "\n",
        "def first_onset_time(y, sr):\n",
        "    on = librosa.onset.onset_detect(y=y, sr=sr, backtrack=True, units=\"time\",\n",
        "                                    pre_max=20, post_max=20)\n",
        "    return float(on[0]) if len(on) else 0.0\n",
        "\n",
        "def shift_audio(y, sr, seconds):\n",
        "    if seconds > 0:\n",
        "        pad = np.zeros(int(seconds * sr), dtype=y.dtype)\n",
        "        return np.concatenate([pad, y], axis=0)\n",
        "    elif seconds < 0:\n",
        "        cut = int(-seconds * sr)\n",
        "        return y[cut:] if cut < len(y) else np.zeros(1, dtype=y.dtype)\n",
        "    return y\n",
        "\n",
        "def to_stereo(y):\n",
        "    return np.stack([y, y], axis=1) if y.ndim == 1 else y\n",
        "\n",
        "# ---------- Tempo fix (try exact, half, double) ----------\n",
        "v_bpm = est_bpm(y_v, sr)\n",
        "b_bpm = est_bpm(y_b, sr)\n",
        "base_rate = v_bpm / max(b_bpm, 1e-9)\n",
        "cands = [base_rate, base_rate * 0.5, base_rate * 2.0]\n",
        "\n",
        "def bpm_after_stretch(rate):\n",
        "    if rate <= 0:\n",
        "        return np.inf\n",
        "    y = librosa.effects.time_stretch(y_b, rate=rate)\n",
        "    # stable estimate using ~30s center window when long\n",
        "    dur = len(y) / sr\n",
        "    if dur > 35:\n",
        "        s = int((dur/2 - 15) * sr)\n",
        "        e = int((dur/2 + 15) * sr)\n",
        "        y = y[s:e]\n",
        "    return est_bpm(y, sr)\n",
        "\n",
        "scores = [(abs(bpm_after_stretch(r) - v_bpm), r) for r in cands]\n",
        "best_diff, best_rate = min(scores, key=lambda x: x[0])\n",
        "\n",
        "print(f\"üß™ BPMs  ‚Üí vocals={v_bpm:.2f} | beat={b_bpm:.2f} | chosen rate={best_rate:.3f}\")\n",
        "\n",
        "y_fix = librosa.effects.time_stretch(y_b, rate=best_rate)\n",
        "\n",
        "# ---------- Beat onset alignment (snap first strong onset to vocals) ----------\n",
        "t_v = first_onset_time(y_v, sr)\n",
        "t_b = first_onset_time(y_fix, sr)\n",
        "shift = t_v - t_b\n",
        "y_fix_aligned = shift_audio(y_fix, sr, shift)\n",
        "print(f\"‚è±Ô∏è Onsets ‚Üí vocals@{t_v:.3f}s | beat@{t_b:.3f}s | shift {shift:+.3f}s\")\n",
        "\n",
        "# ---------- Save fixed beat (stereo) ----------\n",
        "matched_beat_fixed = os.path.join(OUTPUTS_DIR, \"matched_beat_fixed.wav\")\n",
        "sf.write(matched_beat_fixed, to_stereo(y_fix_aligned), sr)\n",
        "print(f\"üíæ Saved fixed beat ‚Üí {matched_beat_fixed}\")\n",
        "\n",
        "# ---------- Mix & export ----------\n",
        "vocals = AudioSegment.from_file(VOCALS_PATH)\n",
        "beat   = AudioSegment.from_file(matched_beat_fixed)\n",
        "\n",
        "# headroom\n",
        "vocals = vocals.apply_gain(-1.0)\n",
        "beat   = beat.apply_gain(-2.0)\n",
        "\n",
        "# loop/trim to vocals length\n",
        "if len(beat) < len(vocals):\n",
        "    beat = beat * math.ceil(len(vocals) / len(beat))\n",
        "beat = beat[:len(vocals)]\n",
        "\n",
        "REMIX_OUT = os.path.join(OUTPUTS_DIR, \"remix_output_fixed.wav\")\n",
        "remix = vocals.overlay(beat)\n",
        "remix.export(REMIX_OUT, format=\"wav\")\n",
        "print(f\"‚úÖ Remix exported ‚Üí {REMIX_OUT}\")\n",
        "\n",
        "# ---------- Play ----------\n",
        "display(Audio(REMIX_OUT))\n"
      ],
      "metadata": {
        "id": "1kKEKuoAeuG9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}